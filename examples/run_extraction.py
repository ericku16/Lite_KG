import os
import sys
from dotenv import load_dotenv

# --- æ­¥é©Ÿï¼šå°‡ src ç›®éŒ„æ·»åŠ åˆ° Python è·¯å¾‘ä¸­ ---
# å¾ 'src/light_kg' å°å…¥ 'Extractor'
script_dir = os.path.dirname(__file__)

# å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼Œå³ 'examples' çš„ä¸Šä¸€å±¤
project_root = os.path.abspath(os.path.join(script_dir, '..'))

# å–å¾— 'src' è³‡æ–™å¤¾çš„è·¯å¾‘
src_root = os.path.join(project_root, 'src')

# å°‡ 'src' è³‡æ–™å¤¾æ·»åŠ åˆ° Python æœå°‹è·¯å¾‘çš„æœ€å‰é¢
sys.path.insert(0, src_root)

try:
    # å°å…¥ Extractor 
    from light_kg.extractor import Extractor
except ImportError:
    print("âŒ éŒ¯èª¤: ç„¡æ³•å°å…¥ 'light_kg' æ¨¡çµ„")
    print(f"  è«‹ç¢ºä¿ 'src' ç›®éŒ„ä½æ–¼: {src_root}")
    print("  ä¸¦ä¸” 'src' ç›®éŒ„ä¸‹æœ‰ 'light_kg' è³‡æ–™å¤¾")
    sys.exit(1)

# ==============================================================================
# --- ä¸»è¦è¨­å®š  ---
# ==============================================================================

# 1. é¸æ“‡ LLM Provider: "openai" æˆ– "ollama"
PROVIDER = "openai" 

# 2. æ ¹æ“š Provider é¸æ“‡æ¨¡å‹
MODEL_NAME = "gpt-4o" if PROVIDER == "openai" else "mistral:latest"

# 3. è¨­å®š NER è·¯å¾‘
NER_MODEL_PATH = os.path.join(project_root, "model", "ner_model", "final-model.pt")

# 4. è¨­å®šè³‡æ–™å¤¾è·¯å¾‘ 
DOCUMENTS_FOLDER = os.path.join(script_dir, "example")
OUTPUT_FOLDER = os.path.join(script_dir, "output")

# 5. å…¶ä»–è¨­å®š 
CHUNK_SIZE = 5000
DELAY_BETWEEN_CHUNKS = 3 if PROVIDER == "openai" else 0

# ==============================================================================
# --- ä¸»åŸ·è¡Œå‡½å¼ ---
# ==============================================================================

def main():
    
    # --- è¼‰å…¥ API é‡‘é‘° ---
    load_dotenv(os.path.join(project_root, '.env'))
    api_key = os.getenv("OPENAI_API_KEY")

    if PROVIDER == "openai" and not api_key:
        print("âŒ éŒ¯èª¤: 'openai' provider éœ€è¦ OPENAI_API_KEYï¼Œè«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š")
        return

    # --- æª¢æŸ¥è·¯å¾‘ ---
    if not os.path.exists(NER_MODEL_PATH):
        print(f"âŒ éŒ¯èª¤: NER æ¨¡å‹è·¯å¾‘ä¸å­˜åœ¨: {NER_MODEL_PATH}")
        print(f"  è«‹åœ¨ 'examples/run_extraction.py' ä¸­æ›´æ–° 'NER_MODEL_PATH' è®Šæ•¸")
        print(f"  å¯¦éš›æ¨¡å‹æª”æ¡ˆæ‡‰ä½æ–¼: {os.path.join(project_root, 'model', 'ner_model', 'final-model.pt')}")
        return

    if not os.path.exists(DOCUMENTS_FOLDER):
        print(f"âš ï¸ è­¦å‘Š: æ–‡ä»¶è³‡æ–™å¤¾ '{DOCUMENTS_FOLDER}' ä¸å­˜åœ¨")
        print("  æ­£åœ¨ç‚ºæ‚¨å»ºç«‹è³‡æ–™å¤¾ï¼Œè«‹åœ¨åŸ·è¡Œå‰æ”¾å…¥ .txt æˆ– .pdf æª”æ¡ˆ")
        os.makedirs(DOCUMENTS_FOLDER, exist_ok=True)
        return

    # --- ç¢ºä¿è¼¸å‡ºè³‡æ–™å¤¾å­˜åœ¨ ---
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)
    
    # --- å‹•æ…‹è¨­å®šè¼¸å‡ºæª”æ¡ˆåç¨± ---
    output_filename = f"result_{PROVIDER}_{MODEL_NAME.replace(':', '_')}.json"
    output_json_path = os.path.join(OUTPUT_FOLDER, output_filename)

    # --- 1. åˆå§‹åŒ– Extractor ---
    print(f"--- æ­£åœ¨åˆå§‹åŒ– Extractor (æ¨¡å‹: {PROVIDER} / {MODEL_NAME}) ---")
    try:
        extractor = Extractor(
            provider=PROVIDER,
            model_name=MODEL_NAME,
            ner_model_path=NER_MODEL_PATH,
            api_key=api_key
        )
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ– Extractor å¤±æ•—: {e}")
        return

    # --- 2. åŸ·è¡Œè™•ç† ---
    extractor.process_documents(
        folder_path=DOCUMENTS_FOLDER,
        output_json_path=output_json_path,
        chunk_size=CHUNK_SIZE,
        delay_between_chunks=DELAY_BETWEEN_CHUNKS
    )

    print(f"\nğŸ‰ åŸ·è¡Œå®Œç•¢ï¼çµæœå·²å„²å­˜è‡³:\n{output_json_path}")

# --- ç¨‹å¼åŸ·è¡Œå…¥å£ ---
if __name__ == "__main__":
    main()